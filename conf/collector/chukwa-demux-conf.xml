<?xml version="1.0"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<?xml-stylesheet type="text/xsl"  href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<!-- Chukwa Job parameters -->
	<property>
	  <name>io.sort.mb</name>
	  <value>64</value>
	  <description>The total amount of buffer memory to use while sorting
	  files, in megabytes.  By default, gives each merge stream 1MB, which
	  should minimize seeks.</description>
	</property>

	<property>
	  <name>fs.inmemory.size.mb</name>
	  <value>64</value>
	  <description>The size of the in-memory filsystem instance in MB</description>
	</property>

	<property>
	  <name>io.sort.factor</name>
	  <value>10</value>
	  <description>The number of streams to merge at once while sorting
	  files.  This determines the number of open file handles.</description>
	</property>

<!-- Archive configuration -->
  
    <property>
       <name>archive.grouper</name>
       <value>Stream</value>
       <description>How to group archive files. Choices are Hourly, Daily, DataType, and Stream.</description>
    </property>

    <property>
       <name>archive.groupByClusterName</name>
       <value>false</value>
       <description>Whether the DataType grouper should group archived files by cluster name.</description>
    </property>

<!-- PostProcessorManager config -->
  <property>
    <name>chukwa.data.loader.threads.limit</name>
    <value>3</value>
    <description>Reduce count </description>
  </property>

  <property>
    <name>chukwa.post.demux.data.loader</name>
    <value>org.apache.hadoop.chukwa.dataloader.MetricDataLoaderPool,org.apache.hadoop.chukwa.dataloader.FSMDataLoader</value>
  </property>

  <property>
    <name>chukwa.post.demux.success.action</name>
    <value></value>
    <description>Comma-separated list of
    org.apache.hadoop.chukwa.datatrigger.TriggerAction implementations
    that will be triggered upon a successful Demux/PostProcessor job</description>
  </property>

  <property>
    <name>post.process.max.error.count.before.shutdown</name>
    <value>4</value>
    <description>The number of consecutive errors to be encountered by the
    PostProcessorManager before the process will be shut down. Set to -1 to continue
    running despite error count.</description>
  </property>

<!-- -->

<!-- ArchiveManager config -->
  
  <property>
    <name>chukwaArchiveBuilder.reduceCount</name>
    <value>5</value>
    <description>Reduce count </description>
  </property>

  <property>
    <name>archive.max.error.count.before.shutdown</name>
    <value>4</value>
    <description>The number of consecutive errors to be encountered by the
    ArchiveManager before the process will be shut down. Set to -1 to continue
    running despite error count.</description>
  </property>

<!-- -->

<!-- Demux configs -->

  <property>
    <name>demux.max.error.count.before.shutdown</name>
    <value>5</value>
    <description>The number of consecutive errors to be encountered by the
    DemuxManager before the process will be shut down. Set to -1 to continue
    running despite error count.</description>
  </property>

<!-- -->  

<!-- Demux aliases -->

  <property>
    <name>HadoopMetrics</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.HadoopMetricsProcessor</value>
    <description>Parser class for Hadoop Metrics </description>
  </property>

  <property>
    <name>SysLog</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.SysLog</value>
    <description>Parser class for </description>
  </property>

  <property>
    <name>Df</name>
<!--    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.Df</value>-->
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.df.Df</value>
    <description>Parser class for </description>
  </property>

  <property>
    <name>Ipmi</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.ipmi.Ipmi</value>
    <description>Parser class for </description>
  </property>


  <property>
    <name>HadoopLog</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.HadoopLogProcessor</value>
    <description>Parser class for </description>
  </property>

  <property>
    <name>Iostat</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.Iostat</value>
    <description>Parser class for </description>
  </property>
 
   <property>
    <name>PbsNodes</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.PbsNodes</value>
    <description>Parser class for </description>
  </property>
 
   <property>
    <name>Sar</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.Sar</value>
    <description>Parser class for </description>
  </property>

   <property>
    <name>TsProcessor</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.TsProcessor</value>
    <description>Parser class for </description>
   </property>
  
   <property>
    <name>Top</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.Top</value>
    <description>Parser class for </description>
   </property>

   <property>
    <name>Torque</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.Torque</value>
    <description>Parser class for Parsing qstat and tracejob</description>
   </property>
  
   <property>
    <name>DbLoader</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.TsProcessor</value>
    <description>Parser class for </description>
   </property>

   <property>
    <name>JobHistory</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.JobLog</value>
    <description>Parser class for Job History Log File</description>
   </property>

   <property>
    <name>JobConf</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.JobConfProcessor</value>
    <description>Parser class for Map reduce Job Configuration</description>
   </property>
    
   <property>
     <name>ClientTrace</name>
     <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.ClientTraceProcessor</value>
     <description>Parser class for TaskTracker and DataNode clienttrace data</description>
   </property>
 
   <property>
    <name>HDFSUsage</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.JPluginMapper</value>
    <description></description>
   </property>

   <property>
    <name>ChukwaMetrics</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.ChukwaMetricsProcessor</value>
    <description></description>
   </property>

   <property>
    <name>SystemMetrics</name>
<!--   <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.SystemMetrics</value>-->
  <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.system.SystemMetricsNG</value>
    <description></description>
   </property>

   <property>
    <name>JobSummary</name>
    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.JobSummary</value>
   </property>
	
	   <property>
    <name>KvmTop</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.kvmtop.KvmTop</value>
   </property>

   <property>
    <name>Hardware</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.h.Hardware</value>
   </property>

   <property>
    <name>HUtil</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.hutil.HUtil</value>
   </property>

   <property>
    <name>HDisk</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.hdisk.HDisk</value>
   </property>

   <property>
    <name>HFilesystem</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.hfilesystem.HFilesystem</value>
   </property>

   <property>
    <name>HDiskUtil</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.hdiskutil.HDiskUtil</value>
   </property>

   <property>
    <name>VM</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.vm.VM</value>
   </property>

   <property>
    <name>HPower</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.hpower.HPower</value>
   </property>

   <property>
    <name>HPowerUtil</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.hpowerutil.HPowerUtil</value>
   </property>

   <property>
    <name>VmMetadata</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.vmmetadata.VmMetadata</value>
   </property>
   
   <property>
    <name>Visor</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.visor.Visor</value>
   </property>
   
    <property>
    <name>WriteState</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.writestate.WriteState</value>
   </property>
   
   <property>
    <name>DeleteVM</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.deletevm.DeleteVM</value>
   </property>
   
   <property>
    <name>AppInstanceDeployed</name>
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.appinstance.AppInstanceDeployed</value>
   </property>
	
   <property>
    <name>VirtTop</name>
<!--    <value>org.apache.hadoop.chukwa.extraction.demux.processor.mapper.VirtTop</value>-->
    <value>eu.cactosfp7.datacollection.chukwa.demux.mapper.virttop.VirtTop</value>
   </property>
</configuration>